{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOMATIC REVIEW CLASSIFIER\n",
    "\n",
    "In this NLP project classifying Yelp Reviews into positive or negative review based off the text content in the reviews. I'm going to use the data labeled with 1(negative opinion) and 5(positive opinion) stars. In order to do this several algorithms has been used, on this notebook a Naive Bayes method is deployed as a baseline and a Logistic Regression is choosen as it shows the best results. \n",
    "\n",
    "I'm using the [Yelp Review Data Set from Kaggle](https://www.kaggle.com/c/yelp-recsys-2013)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other techniques of tokenization are stemmers (reduce words to it's root (ran, running, runner ==> run))\n",
    "# or categorization on verbds, adj...\n",
    "\n",
    "def tokenize_text(document):\n",
    "    stemmer = PorterStemmer()\n",
    "    #decode\n",
    "    doc_decoded = [word.decode('utf-8') for word in document.split()]\n",
    "    \n",
    "    doc_decoded = ' '.join(doc_decoded)\n",
    "    \n",
    "    # Check characters to see if they are in punctuation\n",
    "    no_punc = [char for char in doc_decoded if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    no_punc = ''.join(no_punc)\n",
    "    \n",
    "    # remove capital letters\n",
    "    no_upper = [word.lower() for word in no_punc.split()]\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    no_stopwords = [word for word in no_upper if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    # stemmer\n",
    "    stemmed = [stemmer.stem(word) for word in no_stopwords]\n",
    "    \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             review\n",
       "0  positive  My wife took me here on my birthday for breakf...\n",
       "1  positive  I have no idea why some people give bad review...\n",
       "3  positive  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4  positive  General Manager Scott Petello is a good egg!!!...\n",
       "6  positive  Drop what you're doing and drive here. After I..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('yelp.csv')\n",
    "\n",
    "df = df[['stars', 'text']]\n",
    "df.columns  = ['label','review']\n",
    "\n",
    "df = df.loc[(df['label'] == 5) | (df['label'] == 1)]\n",
    "\n",
    "df.loc[(df['label'] == 5),'label'] = 'positive'\n",
    "df.loc[(df['label'] == 1),'label'] = 'negative'\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive reviews:  81.669114048\n",
      "negative reviews:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "positive    81.669114\n",
       "negative    18.330886\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    82.129743\n",
      "negative    17.870257\n",
      "Name: label, dtype: float64\n",
      "positive    79.828851\n",
      "negative    20.171149\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print y_train.value_counts(normalize=True) * 100\n",
    "print y_test.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90       816\n",
      "          1       0.01      1.00      0.03         2\n",
      "\n",
      "avg / total       1.00      0.82      0.90       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bag of words', CountVectorizer(analyzer=tokenize_text)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95       664\n",
      "          1       0.79      0.78      0.78       154\n",
      "\n",
      "avg / total       0.92      0.92      0.92       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('bag of words', CountVectorizer(analyzer=tokenize_text)),\n",
    "    ('tfidf', TfidfTransformer(norm=None)),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipeline2.fit(X_train,y_train)\n",
    "predictions = pipeline2.predict(X_test)\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.94      0.96       698\n",
      "          1       0.73      0.93      0.82       120\n",
      "\n",
      "avg / total       0.95      0.94      0.94       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline3 = Pipeline([\n",
    "    ('bag of words', CountVectorizer(analyzer=tokenize_text)),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "pipeline3.fit(X_train,y_train)\n",
    "predictions = pipeline3.predict(X_test)\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.93      0.96       701\n",
      "          1       0.70      0.91      0.79       117\n",
      "\n",
      "avg / total       0.94      0.93      0.93       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline4 = Pipeline([\n",
    "    ('bag of words', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipeline4.fit(X_train,y_train)\n",
    "predictions = pipeline4.predict(X_test)\n",
    "print(classification_report(predictions,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINDINGS:\n",
    "\n",
    "- On the first pipeline the results are very bad (always classifies as positive). This is due the preprocessing, tf-idf does not provide useful data if the data isn't normalized.\n",
    "- The second pipeline brings the best results activating the normalization parameter (79 % on negative detection / 95% on positive).\n",
    "- The next one performs well without the tf-idf.\n",
    "- The last one uses the default CountVectorizer analyzer. It performs a little bit worse but is faster (due python internal optimizations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.97       678\n",
      "          1       0.81      0.88      0.84       140\n",
      "\n",
      "avg / total       0.95      0.94      0.94       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline5 = Pipeline([\n",
    "    ('bag of words', CountVectorizer()),\n",
    "    ('tf-idf', TfidfTransformer(norm=None)),\n",
    "    ('classifier', LogisticRegression()), \n",
    "])\n",
    "\n",
    "pipeline5.fit(X_train,y_train)\n",
    "predictions = pipeline5.predict(X_test)\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('bag of words', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "  ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'classifier__C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_ = {'classifier__C': [1e-5, 1e-3, 1e-1, 1e0, 1e1, 1e2]}\n",
    "bow_search = GridSearchCV(pipeline5, cv=5, param_grid=param_grid_)\n",
    "bow_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.96      0.97       683\n",
      "          1       0.80      0.90      0.85       135\n",
      "\n",
      "avg / total       0.95      0.95      0.95       818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = bow_search.best_params_['classifier__C']\n",
    "\n",
    "pipeline6 = Pipeline([\n",
    "    ('bag of words', CountVectorizer()),\n",
    "    ('tf-idf', TfidfTransformer(norm=None)),\n",
    "    ('classifier', LogisticRegression(C=c)), \n",
    "])\n",
    "\n",
    "pipeline6.fit(X_train,y_train)\n",
    "predictions = pipeline6.predict(X_test)\n",
    "\n",
    "print(c)\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MORE FINDINGS:\n",
    "\n",
    "- Logistic regression performs better classification\n",
    "- Multiple experiments has been done with GridSearchCv. Finally a regularization C = 0.1 brings the best results.\n",
    "- The choosen system is:\n",
    "    * default vectorizer analyzer\n",
    "    * tf-idf without normalization\n",
    "    * logistic regressor classifier with c=0.1\n",
    "    * Detection Rate (DR) and False Alarm Rate(FAR): positve class (DR=98%, FAR=96%); negative class (DR=80%, FAR=90%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
